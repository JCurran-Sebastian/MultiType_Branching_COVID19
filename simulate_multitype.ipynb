{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy.linalg as nla\n",
    "import seaborn as sns\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import multitype_new as mt\n",
    "import importlib\n",
    "importlib.reload(mt)\n",
    "from scipy.integrate import odeint\n",
    "from joblib import Parallel, delayed\n",
    "from time import time\n",
    "\n",
    "# Parameters to change \n",
    "ntypes = 8\n",
    "# Number of types-at-birth\n",
    "nexposed = int(ntypes/2)\n",
    "\n",
    "\n",
    "# Disease Parameters\n",
    "\n",
    "gamma = 0.25 # Recovery Rate\n",
    "sigma = 1/3  # Progression rate from exposed to infectious\n",
    "\n",
    "beta_baseline = 0.675\n",
    "\n",
    "print('Running for beta = ' + str(beta_baseline))\n",
    "\n",
    "const_vec = np.squeeze(pd.read_csv('const_vec_in.csv',header=None).to_numpy()) #np.array((1., sus_ur, sus_vu, sus_vr))\n",
    "prop_vec = np.squeeze(pd.read_csv('prop_vec_in.csv',header=None).to_numpy()) #np.array((p_sus*p_no_vac, p_rec*p_no_vac, p_sus*p_vac, p_rec*p_vac))\n",
    "\n",
    "scale = const_vec*prop_vec\n",
    "\n",
    "epsilon = 1e-3\n",
    "RV = beta_baseline/gamma\n",
    "\n",
    "Tmax = 400 \n",
    "num = Tmax \n",
    "time_vec = np.linspace(0, Tmax, num=num)\n",
    "dtime = time_vec[1]-time_vec[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = 0\n",
    "im_vec = np.zeros(ntypes)\n",
    "y0 = np.zeros(ntypes)\n",
    "y0[0] = 1\n",
    "ics = np.zeros(ntypes)\n",
    "def eta(t):\n",
    "    return im_vec\n",
    "\n",
    "trans_vec = np.ones(nexposed)\n",
    "\n",
    "def lifetime_vec(beta, gamma, sigma, ntypes = ntypes, const_vec = const_vec, prop_vec = prop_vec, trans_vec = trans_vec):\n",
    "    nexposed = int(ntypes / 2)\n",
    "    omega_vec = sigma * np.ones(ntypes) \n",
    "\n",
    "        \n",
    "    for nex in range(0, nexposed):\n",
    "        omega_vec[nex + nexposed] = np.sum(const_vec*prop_vec*beta)*trans_vec[nex] + gamma\n",
    "    return omega_vec\n",
    "\n",
    "omega_vec = lifetime_vec(beta_baseline, gamma, sigma)\n",
    "\n",
    "def P(u, t): # Offspring distribution\n",
    "\n",
    "        ## Returns a vector of length ntypes with entry i containing  probabilities of generating particles \n",
    "        ## of each type from a particle of type i\n",
    "\n",
    "        pvec = np.zeros_like(u)\n",
    "        nexposed = int(ntypes/2)\n",
    "        omega = (np.sum(prop_vec * const_vec * beta_baseline) + gamma)\n",
    "        \n",
    "\n",
    "        sum_gen_funcs = np.sum((beta_baseline*prop_vec/omega)*const_vec*u[:nexposed])\n",
    "         \n",
    "        for nex in range(0, nexposed):\n",
    "\n",
    "            pvec[nex] = u[nex+nexposed] \n",
    "            pvec[nex+nexposed] =  u[nex+nexposed] * sum_gen_funcs  + (gamma/omega)\n",
    "        \n",
    "        return pvec  \n",
    "\n",
    "def Jacobian_mat(beta, gamma, sigma, ntypes = ntypes, const_vec = const_vec, prop_vec = prop_vec, trans_vec = trans_vec, omega_vec = omega_vec):\n",
    "    \n",
    "    # Jacobian of the offspring distribution - corresponding to \\Omega\n",
    "\n",
    "    Omat = np.zeros((ntypes, ntypes))\n",
    "    omega_vec = sigma * np.ones(ntypes)       \n",
    "    nexposed = int(ntypes/2)\n",
    "    for nex in range(0, nexposed):\n",
    "        omega_vec[nex + nexposed] = np.sum(const_vec*prop_vec*beta)*trans_vec[nex] + gamma\n",
    "        Omat[nex, nex+nexposed] = omega_vec[nex]\n",
    "        Omat[nex+nexposed, :nexposed] = const_vec*prop_vec*beta *trans_vec[nex]\n",
    "        Omat[nex+nexposed, nex+nexposed] = np.sum(const_vec * beta * prop_vec)*trans_vec[nex]\n",
    "\n",
    "    Omat -= np.diag(omega_vec)\n",
    "    return Omat\n",
    "\t\n",
    "\t\n",
    "rho = (odeint(mt.set_odes, ics, time_vec, args = (P, omega_vec)).T )\n",
    "q = np.ones_like(time_vec)\n",
    "for i in range(ntypes):\n",
    "    q *= rho[i, :] ** y0[i]\n",
    "\n",
    "np.savetxt('./Outputs_for_matlab/p_extinction/p_extinction_R=' + str(RV) + '.csv', np.vstack((time_vec, q)))\n",
    "\n",
    "# Jacobian, or mean matrix\n",
    "Omat = Jacobian_mat(beta_baseline, gamma, sigma)\n",
    "# Mean of each type\n",
    "Mmat = odeint(mt.set_mean_odes, y0, time_vec, args = (Omat,)).T\n",
    "# Total mean\n",
    "mean = np.sum(Mmat, axis=0)\n",
    "\n",
    "variance = mt.variance(time_vec, y0, omega_vec, Omat, [prop_vec, const_vec, sigma, \n",
    "                                                   beta_baseline, gamma], eta)\n",
    "\n",
    "#Coefficient of variation\n",
    "sig_over_mean = (np.sqrt(variance)/(mean))\n",
    "\t\n",
    "Tstar_idx, Tstar = mt.Tstar(time_vec, q, sig_over_mean, thresh1 = epsilon, thresh2 = epsilon)\n",
    "Zstar_min= mean[Tstar_idx]\n",
    "\n",
    "eigvls, orth = nla.eig(Omat)\n",
    "orth = np.real_if_close(orth)\n",
    "if True:#np.iscomplex(orth).any():\n",
    "\n",
    "# Maybe change this back\n",
    "    print('Numerical instability: Switching to symbolic compution of eigenvectors')\n",
    "    sym_params = [scale[0], scale[1], scale[2], scale[3], sigma, gamma, beta_baseline]\n",
    "    sym_labels = ['a', 'b', 'c', 'd', 's', 'g', 'beta']\n",
    "    sym_dict = dict([(l, p) for (l, p) in zip(*(sym_labels, sym_params))])\n",
    "    diag_sym = mt.Omega_sym(0).diagonalize(normalize = True)\n",
    "    sym_eigvectors = diag_sym[0]\n",
    "    sym_eigvalues = diag_sym[1]\n",
    "    eigvls = np.diag(np.array(sym_eigvalues.subs(sym_dict)))\n",
    "    orth = np.array(sym_eigvectors.subs(sym_dict)).astype(float)\n",
    "assert(not np.iscomplex(orth).any()), 'Jacobian has complex eigendecomposition'\n",
    "eigvls = eigvls.astype('float64')\n",
    "orth = orth.astype('float64')\n",
    "\n",
    "# Some issue with ordering in sympy vs numpy\n",
    "ordering = np.flip(np.argsort(eigvls)).tolist()\n",
    "eigvls, orth = mt.reorder_evecs(eigvls, orth, ordering)\n",
    "\n",
    "\n",
    "diagmat = np.diag(eigvls)\n",
    "growth_rate = np.max(eigvls)\n",
    "assert(growth_rate > 0), 'Growth Rate must be positive (i.e. Branching Process must be supercritical)'\n",
    "\n",
    "orth_inv = mt.invert_mat_safe(orth.copy())\n",
    "orth_c = orth.copy().T\n",
    "orthc_inv = mt.invert_mat_safe(orth_c.copy())\n",
    "\n",
    "\n",
    "### Build variance matrix via Kronecker Products\n",
    "H = np.kron(orth, np.kron((orthc_inv), orthc_inv))\n",
    "Hinv = np.kron(orth_inv, np.kron(orth_c, orth_c)) \n",
    "Amat = np.kron(orthc_inv, orthc_inv)\n",
    "Amat_inv = np.kron(orth_c, orth_c)\n",
    "\n",
    "vec_w = np.zeros(ntypes**3)\n",
    "\n",
    "# Build Hessian matrix\n",
    "Hessian_mat = np.zeros((ntypes, ntypes, ntypes))\n",
    "for level in range(0, nexposed):\n",
    "    for i in range(0, nexposed):\n",
    "\n",
    "        Hessian_mat[level + nexposed, level+nexposed, i] = (beta_baseline * const_vec[i]*prop_vec[i])/(omega_vec[level+nexposed])\n",
    "        Hessian_mat[level + nexposed, i, level+nexposed] = (beta_baseline * const_vec[i]*prop_vec[i])/(omega_vec[level+nexposed])\n",
    "\n",
    "P_mat = np.zeros((ntypes, ntypes))\n",
    "\n",
    "\n",
    "for nex in range(0, nexposed):\n",
    "    P_mat[nex, nex+nexposed] = omega_vec[nex]/omega_vec[nex]\n",
    "    P_mat[nex+nexposed, :nexposed] = const_vec*prop_vec*beta_baseline/omega_vec[nex+nexposed]\n",
    "    P_mat[nex+nexposed, nex+nexposed] = np.sum(const_vec * beta_baseline * prop_vec)/omega_vec[nex+nexposed]\n",
    "\n",
    "P_mat = P_mat.T\n",
    "\n",
    "Gmat = np.zeros((ntypes, ntypes, ntypes))\n",
    "C = np.zeros(ntypes**3)\n",
    "for l in range(0, ntypes):\n",
    "    f_vec = (P_mat - np.identity(ntypes))[l, :]\n",
    "    unitvec = np.zeros(ntypes)\n",
    "    unitvec[l] = 1\n",
    "\n",
    "    Gmat[l, :, :] = Hessian_mat[l, :, :] - np.diag(P_mat[:, l]) \n",
    "    Gmat[l, :, :] += np.diag(unitvec)        \n",
    "    Gmat[l, :, :] *= omega_vec[l]\n",
    "\n",
    "\n",
    "growth_rate = np.max(eigvls)\n",
    "print(growth_rate)\n",
    "\n",
    "escale = (Mmat[:, Tstar_idx] / orth[:, 0])[0]\n",
    "integral_limit = np.sum(Mmat[:, Tstar_idx]/np.sum(orth[:, 0]))\n",
    "\n",
    "\n",
    "Sigma_mat = Jacobian_mat(beta_baseline, gamma = gamma, sigma = sigma)\n",
    "Sigma_mat[nexposed:, :nexposed] = 0\n",
    "T_mat = Jacobian_mat(beta_baseline, gamma = gamma, sigma = sigma) - Sigma_mat\n",
    "next_gen = - T_mat @ nla.inv(Sigma_mat)\n",
    "R_effective = np.max(nla.eigvals(next_gen))\n",
    "print('R_eff = ' + str(R_effective))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sims = 10000\n",
    "\n",
    "class Gillespie:\n",
    "    def __init__(self, rates, transitions, y0):\n",
    "        \n",
    "        assert(len(rates(y0)) == len(transitions))\n",
    "        \n",
    "        self.rates = rates\n",
    "        self.y0 = y0\n",
    "        self.numvars = len(y0)\n",
    "        self.transitions = transitions\n",
    "        return None\n",
    "    \n",
    "    \n",
    "    def Gillespie_trajectory(self, Zstar = None, Tstar = None, max_events = int(1e7)):\n",
    "        rates = self.rates\n",
    "        y0 = self.y0\n",
    "        numvars = self.numvars\n",
    "        transitions = self.transitions\n",
    "        output_mat = np.zeros((numvars+1, max_events))\n",
    "        output_mat[1:, 0] = y0\n",
    "        rands = np.random.random(size = (2, max_events))\n",
    "        t = 0\n",
    "        hitting_time = None\n",
    "        case_check = 0\n",
    "        for i in range(1, max_events):\n",
    "            \n",
    "            # Calculate rates\n",
    "            \n",
    "            rate_vec = rates(output_mat[1:, i-1])\n",
    "            rate_cumsum = np.cumsum(rate_vec)\n",
    "            rate_sum = np.sum(rate_vec)\n",
    "            dt = -np.log(rands[0, i-1])/rate_sum\n",
    "            \n",
    "            # Update\n",
    "            \n",
    "            t += dt\n",
    "            output_mat[0, i] = t\n",
    "            choose_rand_event = rate_sum * rands[1, i-1]\n",
    "            event_index = np.where(rate_cumsum > choose_rand_event)[0][0]\n",
    "            \n",
    "            output_mat[1:, i] = output_mat[1:, i-1] + transitions[event_index]\n",
    "\n",
    "            total_infectious = np.sum(output_mat[1:, i])\n",
    "            if Zstar is not None:\n",
    "                if isinstance(Zstar, int) or isinstance(Zstar, float):\n",
    "                    if total_infectious > Zstar:\n",
    "\n",
    "                        hitting_time = t\n",
    "\n",
    "                        return hitting_time\n",
    "\n",
    "            \n",
    "            if Tstar is not None:\n",
    "                if t > Tstar:\n",
    "                    check_cases = output_mat[1:, i]\n",
    "                    return check_cases\n",
    "                    \n",
    "            if total_infectious == 0:\n",
    "                break\n",
    "            \n",
    "        if Zstar is not None:\n",
    "            return None\n",
    "        elif Tstar is not None:\n",
    "            return None\n",
    "        else:\n",
    "            return output_mat\n",
    "        \n",
    "def do_Gillespie_runs(G, Zstar):\n",
    "    result = None\n",
    "    while result == None:\n",
    "        result = G.Gillespie_trajectory(Zstar = integral_limit)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose index of Istars_min (Z^*) to obtain FPT distribution - improve by doing this for all!! \n",
    "im_gillespie = im\n",
    "\n",
    "def rates(u):           \n",
    "    rates_vec = np.zeros(3*nexposed)\n",
    "    rates_vec[:nexposed] = sigma*np.ones(nexposed)*u[:nexposed]\n",
    "    rates_vec[nexposed:(2*nexposed)] = np.sum(const_vec*prop_vec*beta_baseline*u[nexposed:]) #+ im_gillespie*prop_vec*const_vec\n",
    "    rates_vec[(2*nexposed):(3*nexposed)] = gamma*u[nexposed:]\n",
    "    return rates_vec\n",
    "\n",
    "transitions = {}\n",
    "for i in range(nexposed):\n",
    "    exposed_to_infectious_trans = np.zeros(ntypes) #E_i -> I_i\n",
    "    exposed_to_infectious_trans[i] = -1\n",
    "    exposed_to_infectious_trans[i+nexposed] = 1\n",
    "\n",
    "    transitions[i] = exposed_to_infectious_trans\n",
    "\n",
    "    infection_trans = np.zeros(ntypes)\n",
    "    infection_trans[i] = 1\n",
    "\n",
    "    transitions[i+nexposed] = infection_trans\n",
    "\n",
    "    recovery_trans = np.zeros(ntypes)\n",
    "    recovery_trans[i+nexposed] = -1\n",
    "\n",
    "    transitions[i + 2*nexposed] = recovery_trans\n",
    "\n",
    "\n",
    "y0vec = np.zeros(ntypes)\n",
    "if im_gillespie == 0:\n",
    "    y0vec[0] = 1\n",
    "G = Gillespie(rates, transitions, y0vec)\n",
    "# Reff_cols = [str(Re) for Re in Reff_vec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cores = 6\n",
    "start = time()\n",
    "some_runs = Parallel(n_jobs=n_cores)(delayed(do_Gillespie_runs)(G, integral_limit) for m in range(num_sims))\n",
    "end = time()\n",
    "print('Parallel Gillespie simulations on ' + str(n_cores) + ' cores finished in ' + str(np.round(end - start, 2)) + ' seconds!')\n",
    "sns.kdeplot(some_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in simulation output if not wanting to rerun \n",
    "some_runs = np.genfromtxt(\"./Plotting_Outputs/gillespie_sims_beta=\" + str(beta_baseline) + \".csv\", delimiter=\",\")\n",
    "print('Reading simulation output for beta = ' + str(beta_baseline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (orth[:, 0] < 0).all():\n",
    "    orth = -orth\n",
    "change_from_ebasis = orth \n",
    "\n",
    "evec = change_from_ebasis[:, 0] \n",
    "\n",
    "variance_diffusion_mat = np.zeros((ntypes, ntypes))\n",
    "\n",
    "for l in range(ntypes): \n",
    "    variance_diffusion_mat += Gmat[l, :, :] *evec[l]  \n",
    "variance_all = (orth[:, 0].T@variance_diffusion_mat@orth[:, 0])\n",
    "\n",
    "print('Total variance is ' + str(variance_all))\n",
    "\n",
    "evec_scaling = np.abs(1/np.sum(evec))\n",
    "\n",
    "print('Evec scaling is ' + str(evec_scaling))\n",
    "\n",
    "xvec = np.linspace(np.finfo(float).eps, 20000, int(1e5))\n",
    "xvec_idx = np.min(np.where(xvec>=(evec_scaling*Zstar_min))[0])\n",
    "integral_limit = xvec[xvec_idx]\n",
    "\n",
    "t0 = 0\n",
    "dt = np.diff(time_vec)[0]\n",
    "cmp = sns.color_palette('Set2')\n",
    "\n",
    "stop_cases = [integral_limit]\n",
    "cols = [str(st) for st in stop_cases]\n",
    "\n",
    "\n",
    "def chi_sq(u, x, t):\n",
    "    x_scale = 2*growth_rate*x/(((variance_all/2))*(np.exp(growth_rate*t) - 1))\n",
    "    lamb = 2*growth_rate*np.exp(growth_rate*t)/((variance_all/2)*(np.exp(growth_rate*t) - 1))\n",
    "    chi_sq_pdf = growth_rate/((variance_all/2)*(np.exp(growth_rate*t) - 1)) * np.sqrt(np.exp(growth_rate*t)/x) * np.exp(- 1/2 * (lamb + x_scale)) * sp.special.iv(1, np.sqrt(x_scale*lamb)) / ((1-np.exp(-lamb/2)))\n",
    "    return chi_sq_pdf\n",
    "\n",
    "\n",
    "print('Critical V* = ' +str(xvec[xvec_idx]) + ', critical Z^* is ' + str(Zstar_min))\n",
    "cdf_chisq = np.zeros(len(time_vec))\n",
    "\n",
    "for T_idx, T_val in enumerate(tqdm(time_vec)):\n",
    "    chi_sq_integral = sp.integrate.odeint(chi_sq, 0, xvec, args = (T_val,)).flatten() \n",
    "    prob =  (1-(chi_sq_integral[xvec_idx]))\n",
    "    cdf_chisq[T_idx] = prob\n",
    "    \n",
    "pdf_chisq = np.gradient(cdf_chisq, dt)\n",
    "plt.plot(time_vec, pdf_chisq, label = \"Feller_exact\", color = cmp[1])\n",
    "sns.histplot(some_runs, label = 'Simulations', stat = 'density', color = cmp[2], alpha = 0.5, bins = 40)\n",
    "sns.kdeplot(some_runs, color = cmp[2])\n",
    "plt.xlim([0, 300])\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"./Plotting_Outputs/gillespie_sims_beta=\" + str(beta_baseline) + \".csv\", np.array(some_runs), delimiter=\",\")\n",
    "np.savetxt(\"./Plotting_Outputs/gillespie_pdf_beta=\" + str(beta_baseline) + \".csv\", pdf_chisq,  delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
